{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yahyakkhalid/Twitter-data-sentiment-analysis/blob/main/creation_corpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAbEqfgOzQzf"
      },
      "source": [
        "# Data Scraping en utilisant la librairie Snscrape\n",
        "> #### [Snscrape](https://github.com/JustAnotherArchivist/snscrape) est un scraper pour les services de réseaux sociaux. Il récupère des éléments tels que les profils d'utilisateurs, les hashtags ou les recherches et renvoie les éléments découverts, par ex. les postes concernés.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoVf3VIJzs3e"
      },
      "source": [
        "### Installation du dernier version de la librairie Snscrape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rX8-Y-67zKl2"
      },
      "outputs": [],
      "source": [
        "! pip install -q git+https://github.com/JustAnotherArchivist/snscrape.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D3H3N6rz7ys"
      },
      "source": [
        "### Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQJPKoWc0CNd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEyAIFKJ0UZ9"
      },
      "source": [
        "### Snscraping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtCKAPhbz5Sd"
      },
      "source": [
        "##### Définition des paramètres de scraper des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTOvzHb-0LiM"
      },
      "outputs": [],
      "source": [
        "# Requête (recherche de texte)\n",
        "  # Chercher les tweets du dernier mois\n",
        "tweet_count = 300000\n",
        "text_query = \"covid lang:fr\"\n",
        "since_date = \"2021-12-01\"\n",
        "until_date = \"2022-01-17\"\n",
        "output_file = \"covid-tweets.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGQJ6N4p0azl"
      },
      "source": [
        "##### Utilisation de la bibliothèque OS pour appeler des commandes CLI en Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJuCUT7F0brd"
      },
      "outputs": [],
      "source": [
        "os.system(f\"\"\"\n",
        "  snscrape --jsonl --max-results { tweet_count } twitter-search \"{ text_query }\n",
        "  since:{ since_date }  until:{ until_date }\" > { output_file }\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoiHi-Bw0f3l"
      },
      "source": [
        "##### Lecture du fichier json généré à partir de la commande CLI ci-dessus et crée une dataframe pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiZKHfsw0jUN"
      },
      "outputs": [],
      "source": [
        "tweets_file = output_file\n",
        "cols = ['date', 'content']\n",
        "data = []\n",
        "\n",
        "with open(tweets_file, encoding='utf-16') as file: # Enlever le encoding si une erreur se produit.\n",
        "    for line in file.readlines():\n",
        "      doc = json.loads(line)\n",
        "      lst = [doc['date'], doc['content']]\n",
        "      data.append(lst)\n",
        "\n",
        "tweets_df = pd.DataFrame(data = data, columns = cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPJP0Cbf0v-9"
      },
      "source": [
        "##### Echantillon de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94nUgJvW0yqH"
      },
      "outputs": [],
      "source": [
        "tweets_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJMGdz9q06z-"
      },
      "source": [
        "### Création du corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGuKxMdB0-x9"
      },
      "source": [
        "Création du répertoire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_LcW4DR07eX"
      },
      "outputs": [],
      "source": [
        "corpusdir = 'corpus_tweets/'\n",
        "if not os.path.isdir(corpusdir):\n",
        "    os.mkdir(corpusdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNvBiFSO1Hvs"
      },
      "source": [
        "Exportation des tweets dans des fichiers de nom 'tweet_{id}_{date}.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJ5qP7vY1HEE"
      },
      "outputs": [],
      "source": [
        "for id, row in tweets_df.iterrows():\n",
        "  filename = f'tweet_{ id }_{ pd.to_datetime(row[\"date\"]).date() }.txt'\n",
        "  with open(corpusdir + filename, 'w', encoding=\"utf-8\") as file:\n",
        "    file.write(row['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZvCfepXOBa9"
      },
      "source": [
        "### Zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7K4W8CeJOBI1"
      },
      "outputs": [],
      "source": [
        "shutil.make_archive(corpusdir, 'zip', './')\n",
        "shutil.rmtree(corpusdir)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "creation du corpus",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}